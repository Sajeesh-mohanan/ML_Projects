# ğŸ¦ Twitter Sentiment Analysis using NLP

This project performs **sentiment analysis** on tweets using Natural Language Processing (NLP) techniques and machine learning. It classifies tweets into **positive** or **negative** sentiments using the **Sentiment140 dataset**.

---

## ğŸ“¦ Dataset

- **Source:** [Sentiment140 - Kaggle](https://www.kaggle.com/datasets/kazanova/sentiment140)
- **Content:** 1.6 million tweets labeled as:
  - `0` â†’ Negative sentiment  
  - `4` â†’ Positive sentiment

---

## ğŸ§° Libraries Used

- `pandas`, `numpy`
- `nltk` for text preprocessing
- `scikit-learn` for model building (Logistic Regression)
- `TfidfVectorizer` for feature extraction

---

## ğŸš€ Workflow

1. **Install and authenticate Kaggle API**
2. **Download and extract dataset**
3. **Clean and preprocess tweets**:
   - Remove links, punctuation, and stopwords
   - Apply stemming
4. **Convert text to numerical vectors** using TF-IDF
5. **Train a Logistic Regression model**
6. **Evaluate the model** using accuracy score

---

## ğŸ§ª Model Performance

The model is evaluated on a hold-out test set using `accuracy_score` to measure how well it can predict the sentiment of unseen tweets.

---

## ğŸ“ Project Structure

Twitter_Sentiment_Analysis/
â”‚
â”œâ”€â”€ sentiment_analysis.ipynb # Jupyter Notebook
â”œâ”€â”€ kaggle.json # Kaggle API key (not shared publicly)
â”œâ”€â”€ sentiment140.zip # Raw data (from Kaggle)
â”œâ”€â”€ training.1600000.processed.noemoticon.csv # Dataset file
â””â”€â”€ README.md # Project documentation


---

## ğŸ’¡ Future Improvements

- Try advanced models: SVM, Random Forest, or XGBoost
- Use deep learning (LSTM or BERT)
- Visualize word clouds and frequent terms
- Deploy as a web app using Streamlit

---

## ğŸ“„ License

This project is open-source under the [MIT License](LICENSE).

---

## ğŸ™‹â€â™‚ï¸ Author

**Your Name**  
Feel free to connect or give feedback!